# CPU-Safe Training Guide

## üìã Overview

This guide explains the new **lightweight CPU-optimized version** of the model trainer that prevents system freezes and allows safe CPU-only training while you install CUDA.

---

## üöÄ Why Use CPU-Safe Version?

### Original Issue
- ‚ùå Model too large: 8.5M parameters
- ‚ùå Batch size too large: 16 samples
- ‚ùå Hidden size too large: 512
- ‚ùå Memory demand: 8-10 GB per batch
- ‚ùå CPU gets maxed out ‚Üí **System freeze**

### CPU-Safe Solution
- ‚úÖ Lightweight model: 480K parameters (95% smaller!)
- ‚úÖ Small batch size: 8 samples
- ‚úÖ Reasonable hidden size: 128
- ‚úÖ Memory demand: 1-2 GB per batch
- ‚úÖ CPU usage stays at 50-70% ‚Üí **Safe training**

---

## üìä Comparison: Original vs CPU-Safe

| Metric | Original (Ultimate) | CPU-Safe (Lightweight) |
|--------|-----------------|--------------------|
| **Hidden Size** | 512 | 128 |
| **Num Layers** | 5 | 2 |
| **Total Parameters** | 8.5M | 480K |
| **Batch Size** | 16 | 8 |
| **Dropout** | 0.6 | 0.4 |
| **Architecture** | LSTM+GRU+Transformer | LSTM+GRU |
| **Memory/Batch** | 8-10 GB | 1-2 GB |
| **CPU Usage** | 100% (FREEZE!) | 50-70% (SAFE) |
| **Epoch Time (CPU)** | 20-30 min | 3-5 min |
| **100 Epochs Time** | 30-50 hours | 5-8 hours |
| **100 Epochs Time (GPU)** | 1-2 hours | 30-60 min |

---

## üéØ Three-Phase Training Plan

### Phase 1: CPU-Safe Training (NOW) ‚è±Ô∏è 5-8 hours

```bash
# Safe to run on CPU without system freeze
python train_model_cpu_safe.py --symbol SOL --epochs 100 --batch-size 8
```

**What happens:**
- Model trains safely on CPU
- Memory stays under 3 GB
- CPU usage 50-70% (system responsive)
- Complete in 5-8 hours
- Model saved to `models/saved_models/SOL_cpu_safe_model.pth`

**While training:**
- You can use other programs
- Download CUDA 11.8
- Install PyTorch GPU version
- Prepare your machine

---

### Phase 2: GPU Installation ‚è±Ô∏è 30 minutes

**Install CUDA 11.8:**
https://developer.nvidia.com/cuda-11-8-0-download-archive

**Verify GPU:**
```bash
nvidia-smi
```

**Install PyTorch GPU:**
```bash
pip uninstall torch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Test GPU:**
```python
import torch
print(torch.cuda.is_available())  # Should print True
print(torch.cuda.get_device_name(0))  # Your GPU name
```

---

### Phase 3: GPU Training (AFTER CUDA) ‚è±Ô∏è 1-2 hours

**Run original GPU version:**
```bash
# Much faster with GPU!
python train_model_ultimate.py --symbol SOL --epochs 100 --device cuda
```

**Expected speedup: 50-100x faster!**

---

## üîß Files Explained

### New Files Created

1. **`src/model_trainer_cpu_optimized.py`** (480KB)
   - Lightweight LSTM + GRU models
   - CPU-friendly trainer class
   - Memory monitoring
   - Safe gradient handling

2. **`train_model_cpu_safe.py`** (10KB)
   - Command-line script for CPU training
   - Data fetching from yfinance
   - Simple technical indicators
   - Memory-efficient feature preparation

3. **`CPU_SAFE_TRAINING_GUIDE.md`** (this file)
   - Usage guide
   - Comparisons
   - Training roadmap

### Existing Files (Unchanged)

- ‚úÖ `src/model_trainer_ultimate.py` - Original GPU version (still works)
- ‚úÖ `train_model_ultimate.py` - Original GPU version (still works)
- ‚úÖ `train_model_ultimate_yfinance.py` - YFinance version (still works)

---

## üöÄ Quick Start

### Step 1: Run CPU-Safe Training (NOW)

```bash
cd C:\Users\omt23\PycharmProjects\PythonProject3\crypto-price-predictor

# Train SOL model
python train_model_cpu_safe.py --symbol SOL --epochs 50

# Or with custom settings
python train_model_cpu_safe.py --symbol BTC --epochs 100 --batch-size 8 --learning-rate 0.001
```

### Step 2: While Training, Download CUDA

```
https://developer.nvidia.com/cuda-11-8-0-download-archive
- Select: Windows 10/11 ‚Üí x86_64 ‚Üí exe (local)
- Download (~2.5 GB)
- Install (follow wizard)
```

### Step 3: After CUDA, Upgrade to GPU

```bash
# Install GPU version of PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Run GPU version (50-100x faster!)
python train_model_ultimate.py --symbol SOL --epochs 100 --device cuda
```

---

## üìà Expected Results

### CPU-Safe Training (Phase 1)

```
Epoch  10/100 | Train: 0.052341 | Val: 0.078234 | Mem: 1.2GB
Epoch  20/100 | Train: 0.048932 | Val: 0.075123 | Mem: 1.3GB
Epoch  30/100 | Train: 0.046123 | Val: 0.072456 | Mem: 1.4GB
...
Epoch 100/100 | Train: 0.038234 | Val: 0.058912 | Mem: 1.8GB

Final Validation Loss: 0.058912
Training Time: ~8 hours (CPU)
```

### GPU Training (Phase 3)

Same model, same settings, but:
- **Training time: ~10-15 minutes** (instead of 8 hours!)
- **Memory: ~4-5 GB VRAM** (instead of RAM)
- **Can do 500+ epochs overnight**

---

## ‚öôÔ∏è Configuration Options

### Command-line Arguments

```bash
python train_model_cpu_safe.py [
  --symbol SYMBOL              # BTC, ETH, SOL, etc. (default: BTC)
  --lookback DAYS              # Lookback period (default: 60)
  --epochs N                   # Training epochs (default: 50)
  --batch-size N               # Batch size (default: 8)
  --learning-rate LR           # Learning rate (default: 0.001)
]
```

### Example Commands

```bash
# Quick test (10 epochs, 15 minutes)
python train_model_cpu_safe.py --symbol SOL --epochs 10

# Standard training (50 epochs, 4 hours)
python train_model_cpu_safe.py --symbol BTC --epochs 50

# Deep training (100 epochs, 8 hours)
python train_model_cpu_safe.py --symbol ETH --epochs 100 --batch-size 8

# Custom learning rate
python train_model_cpu_safe.py --symbol SOL --epochs 100 --learning-rate 0.0005
```

---

## üîç Monitoring Training

### Console Output

```
Epoch  10/50 | Train: 0.052341 | Val: 0.078234 | Mem: 1.2GB | LR: 1.00e-03
Epoch  20/50 | Train: 0.048932 | Val: 0.075123 | Mem: 1.3GB | LR: 5.00e-04
Epoch  30/50 | Train: 0.046123 | Val: 0.072456 | Mem: 1.4GB | LR: 5.00e-04
```

### Log File

```bash
# Training logs saved to:
logs/training_cpu_safe.log

# View logs:
type logs\training_cpu_safe.log  # Windows
cat logs/training_cpu_safe.log   # Mac/Linux
```

### Memory Monitoring

The trainer automatically monitors memory:
- ‚úÖ < 3 GB: Safe
- ‚ö†Ô∏è 3-8 GB: Caution
- üî¥ > 8 GB: Danger (reduce batch size)

---

## ‚ùì Troubleshooting

### Issue: Training still slow (2-3 min/epoch)

**Solution: Your CPU is just slow, that's expected**
- Laptop CPUs: 3-5 min/epoch
- Desktop CPUs: 2-3 min/epoch
- GPU: 10-20 sec/epoch (install CUDA)

### Issue: Memory usage still high (> 4 GB)

**Solution: Reduce batch size**
```bash
python train_model_cpu_safe.py --symbol SOL --batch-size 4
```

### Issue: "cuda not found" after CUDA install

**Solution: Reinstall PyTorch**
```bash
pip uninstall torch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Issue: System still freezes

**Solution: Increase lookback period (less data)**
```bash
# Instead of default 60 days
python train_model_cpu_safe.py --symbol SOL --lookback 30 --batch-size 4
```

---

## üìö Model Architecture

### CPU-Safe Model

```
Input: (batch_size, 60 days, 15 features)
   ‚Üì
[LSTM-2] hidden_size=128, dropout=0.4
[GRU-2]  hidden_size=128, dropout=0.4
   ‚Üì
[Fusion Layer] combines LSTM + GRU outputs
   ‚Üì
FC Layers: 256 ‚Üí 128 ‚Üí 64 ‚Üí 1
   ‚Üì
Output: Price prediction

Total Parameters: 480K
Memory per batch (size 8): ~500 MB
```

### Comparison: Ultimate Model

```
Input: (batch_size, 60 days, 17 features)
   ‚Üì
[LSTM-5] hidden_size=512
[GRU-5]  hidden_size=512
[Transformer-4] hidden_size=512
   ‚Üì
[Attention Fusion]
   ‚Üì
FC Layers: 1024 ‚Üí 512 ‚Üí 256 ‚Üí 1
   ‚Üì
Output: Price prediction

Total Parameters: 8.5M
Memory per batch (size 16): ~8-10 GB
```

---

## üéì Learning Path

1. **Now**: CPU-Safe training
   - Learn how model works
   - Understand training process
   - Monitor metrics
   - Takes 5-8 hours

2. **Tomorrow**: Install CUDA
   - Download CUDA 11.8
   - Install PyTorch GPU
   - Test nvidia-smi
   - Takes 30 minutes

3. **Next Day**: GPU training
   - Run full Ultimate model
   - 50-100x speedup
   - Can train overnight
   - Complete in 1-2 hours

---

## üí° Pro Tips

1. **Run overnight**: Start training before sleep, results ready morning
   ```bash
   python train_model_cpu_safe.py --symbol BTC --epochs 100
   ```

2. **Batch multiple symbols**: Train all coins in parallel
   ```bash
   # Terminal 1
   python train_model_cpu_safe.py --symbol BTC --epochs 100
   
   # Terminal 2
   python train_model_cpu_safe.py --symbol ETH --epochs 100
   
   # Terminal 3
   python train_model_cpu_safe.py --symbol SOL --epochs 100
   ```

3. **Monitor in background**: Check logs while training
   ```bash
   tail -f logs/training_cpu_safe.log  # Mac/Linux
   Get-Content -Wait logs\training_cpu_safe.log  # Windows PowerShell
   ```

---

## üìû Support

If you encounter issues:

1. Check logs: `logs/training_cpu_safe.log`
2. Verify CPU cores: Open Task Manager ‚Üí Performance
3. Check free RAM: `python -c "import psutil; print(psutil.virtual_memory())"`
4. Review this guide for your specific issue

---

**Status**: ‚úÖ CPU-Safe version ready to use
**Next**: Download CUDA 11.8 while training
**Final**: GPU version will be 50-100x faster!
